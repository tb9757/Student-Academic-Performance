{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Machine Learning: Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Build a linear regression model\n",
        "* Build a pipeline model which includes scaling\n",
        "* Consider **hypothesis 4** by comparing the models\n",
        "* Use the model to evaluate **hypothesis 2**\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Cleaned CSV file \"academic_performance_cleaned.csv\" \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* A pipeline which performs linear regression on the dataset. I hope to output this to a streamlit app "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data and Prepare for Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First step is to import packages. This time I will be including packages that I will be needing from sklearn so that I can perform linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import data manipulation and visualisation packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split \n",
        "#set seaborn style so plots look nice\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load dataset and display first 10 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/academic_performance_cleaned.csv\")\n",
        "#display first 10 rows of the dataset\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the CSV is saved and loaded it resets the datatypes to int64, so I will change datatypes from int64 to int8 to save memory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#change datatypes to save memory\n",
        "df = df.astype({col: 'int8' for col in df.select_dtypes('int64').columns})\n",
        "#display datatypes\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Linear regression is used to model the relationship between a dependent variable and one or more independent variables. It is the perfect model for this dataset WHYWHYWHYWHYWHY\n",
        "\n",
        "Linear regression requires numerical data only and WHAT DOES IT DO?? Precdiction\n",
        "\n",
        "Before I perform linear regression I need to clean the data. The Study Group column, which was generated for statistical analysis, is categorical and so cannot be considered by the regression algorithm without one hot encoding it. The information in the study group column is represented numerically by the column daily study hours so the study group column is redundant. Leaving it in would make the results misleading as it would be double counting the same metric. \n",
        "\n",
        "The same can be said for the two internal test score columns which also need to be removed. These have been summarised in one column: average test scores. Leaving them in would again mislead the results of the linear regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Small data cleaning step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reg = df.drop(['Internal Test 1 (out of 40)',\n",
        "       'Internal Test 2 (out of 40)', 'Study Group'], axis=1)\n",
        "df_reg.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hypothesis 4: A fully processed regression pipeline achieves better accuracy than a model without preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EXPLANATION overall plan for H4\n",
        "\n",
        "What does preprocessing mean, why might the data need to be scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split Dataset into Train and Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a supervised learning task which means that the dataset can be thought of as having features and a target variable.\n",
        "\n",
        "The target variable is a column which the model is trying to predict. In this case the target is the final exam marks.\n",
        "\n",
        "The features are the rest of the data in the dataset. \n",
        "\n",
        "The model is trying to answer the question: with a set of unseen features, how accurately can the target variable be predicted. \n",
        "\n",
        "The dataset is split into two sections, the train set and the test set. The model is trained on the train set, it learns what features are important and contibute most to the variance in the target data. The model is then tested on unseen data (the test set) and it predicts what the targets variables are on the unseen data. The model can then compare its predictions of the test data to the actual target values of the test data and can assess how good it was at predicting the target variables. \n",
        "\n",
        "MORE MORE MORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reg.columns.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#split dataset into train and test X represents features (drop target variable) and y represents target variable\n",
        "X = df_reg.drop('Final Exam Marks (out of 100)', axis=1)\n",
        "y = df['Final Exam Marks (out of 100)']\n",
        "#create 4 variables for the X_train and X_test are the features and y_train and y_test are the targets\n",
        "#test_size = 0.2 the dataset is split into 80% train and 20% test, ramdom state provides reproducability \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=101)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspecting the X_train shows us that it no longer contains the final marks column so represents just the features, and inspecting the y_train dataframe shows us that it is just the the final marks i.e. the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#features only\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#targets only\n",
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Printing the shape of the datafames shows us that the train set is now 1600 rows (80% of 2000) and the test set is 400 rows (20%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print the shape of the train and test sets\n",
        "print(\n",
        "    \"Train set:\",\n",
        "    X_train.shape,\n",
        "    y_train.shape,\n",
        "    \"\\nTest set:\",\n",
        "    X_test.shape,\n",
        "    y_test.shape,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline linear regression model (no pre-processing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "#save regression scores as a dictionary\n",
        "reg_scores = {\"Model\": \"Baseline\",\n",
        "              \"R2 Score\": r2_score(y_test, prediction), \n",
        "              \"MAE\": mean_absolute_error(y_test, prediction),\n",
        "              \"MSE\": mean_squared_error(y_test, prediction),\n",
        "              \"RMSE\": np.sqrt(mean_squared_error(y_test, prediction))\n",
        "              }\n",
        "\n",
        "# save regression scores in a dataframe for easy comparison\n",
        "df_reg_scores = pd.DataFrame([reg_scores])\n",
        "df_reg_scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "not considering coeffieients because they're not scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear Regression pipeline with pre-processing (feature scaling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I will use the pipeline to pre-process i.e. I will get it to scale the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "#build a pipeline with 3 steps: scaling, selecting best features, ML model\n",
        "def linear_regression_pipeline():\n",
        "    pipeline = Pipeline(\n",
        "        [\n",
        "            ('feature_scaling', StandardScaler()),\n",
        "            ('model', LinearRegression())\n",
        "        ]\n",
        "    )\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "linear_regression_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#fit X_train and y_train with the pipeline\n",
        "pipeline = linear_regression_pipeline()\n",
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_prediction = pipeline.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_reg_scores = {\"Model\": \"Scaled Regression\",\n",
        "                       \"R2 Score\": r2_score(y_test, pipeline_prediction), \n",
        "                       \"MAE\": mean_absolute_error(y_test, pipeline_prediction),\n",
        "                       \"MSE\": mean_squared_error(y_test, pipeline_prediction),\n",
        "                       \"RMSE\": np.sqrt(mean_squared_error(y_test, pipeline_prediction))\n",
        "              }\n",
        "# add new scores to old table\n",
        "df_reg_scores.loc[len(df_reg_scores)] = pipeline_reg_scores\n",
        "df_reg_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# H2 Use feature selection to give me the feature that BLAH "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature selection gives us the feature that explains the most variance in the target (DOES IT?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I'm going to add a feature selection stage to my pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "#build a pipeline with 3 steps: scaling, selecting best features, ML model\n",
        "def feature_selection_pipeline():\n",
        "    pipeline = Pipeline(\n",
        "        [\n",
        "            ('feature_scaling', StandardScaler()),\n",
        "            ('feature_selection', SelectFromModel(LinearRegression())),\n",
        "            ('model', LinearRegression())\n",
        "        ]\n",
        "    )\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_pipeline=feature_selection_pipeline()\n",
        "feature_pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.columns[feature_pipeline['feature_selection'].get_support()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_prediction = feature_pipeline.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_selection_reg_scores = {\"Model\": \"Feature Selection Regression\",\n",
        "                                \"R2 Score\": r2_score(y_test, feature_prediction), \n",
        "                                \"MAE\": mean_absolute_error(y_test, feature_prediction),\n",
        "                                \"MSE\": mean_squared_error(y_test, feature_prediction),\n",
        "                                \"RMSE\": np.sqrt(mean_squared_error(y_test, feature_prediction))\n",
        "              }\n",
        "# add new scores to old table\n",
        "df_reg_scores.loc[len(df_reg_scores)] = feature_selection_reg_scores\n",
        "df_reg_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My goal was to show that average test score is the feature that has the most importance, as predicted earlier by the correlation coefficients. This result indicates that this is the case, but I was not sure that I had done the correct thing. \n",
        "\n",
        "I put my pipeline into chat GPT and asked it to evaluate my reasoning. It informed me that using linear regression inside of SelectFromModel can provide misleading. Below I have quoted the reasoning from GPT\n",
        "\n",
        "\"Lasso regression should be used for feature selection instead of a standard linear regression model because it includes an L1 regularisation penalty that shrinks weaker coefficients toward zero. This allows the model to effectively identify and remove features that contribute little unique predictive value, particularly in the presence of multicollinearity. In contrast, ordinary least squares regression does not apply coefficient penalisation, meaning its coefficients can remain unstable and unsuitable for feature selection. Therefore, Lasso provides a more robust and interpretable approach to identifying the most important predictors in the dataset.\"\n",
        "\n",
        "I will run the pipeline again and replace linear regression with Lasso to see if it makes a difference. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lasso pipeline\n",
        "from sklearn.linear_model import Lasso\n",
        "def lasso_pipeline():\n",
        "    pipeline = Pipeline(\n",
        "        [\n",
        "            ('feature_scaling', StandardScaler()),\n",
        "            ('feature_selection', SelectFromModel(Lasso(alpha=0.1))),\n",
        "            ('model', LinearRegression())\n",
        "        ]\n",
        "    )\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lasso_pipeline = lasso_pipeline()\n",
        "lasso_pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.columns[lasso_pipeline['feature_selection'].get_support()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lasso_prediction = lasso_pipeline.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Lasso_reg_scores = {\"Model\": \"Lasso Regression\",\n",
        "                    \"R2 Score\": r2_score(y_test, lasso_prediction), \n",
        "                    \"MAE\": mean_absolute_error(y_test, lasso_prediction),\n",
        "                    \"MSE\": mean_squared_error(y_test, lasso_prediction),\n",
        "                    \"RMSE\": np.sqrt(mean_squared_error(y_test, lasso_prediction))\n",
        "              }\n",
        "# add new scores to old table\n",
        "df_reg_scores.loc[len(df_reg_scores)] = Lasso_reg_scores\n",
        "df_reg_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
